{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"./img/oscon.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Abstraction layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import cm\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.contrib import layers\n",
    "from sklearn import datasets, metrics, preprocessing\n",
    "from sklearn import model_selection\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "from keras import utils\n",
    "from keras.datasets import mnist\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap,aspect='auto')\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# learn\n",
    "~~~python \n",
    "from tensorflow.contrib import learn\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Estimators\n",
    "### 1. Instantiate the Estimator class\n",
    "~~~python \n",
    "model = learn.<Estimator>()\n",
    "~~~\n",
    "### 2.  Fit it using training data\n",
    "~~~python \n",
    "model.fit()\n",
    "~~~\n",
    "### 3. Evaluate how good is the fit\n",
    "~~~python \n",
    "model.evaluate()\n",
    "~~~\n",
    "### 4. Predict outcomes on new data\n",
    "~~~python \n",
    "model.predict()\n",
    "~~~\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Deep Neural Network Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "DATA_DIR = '/tmp/data' if not 'win32' in sys.platform else \"c:\\\\tmp\\\\data\"\n",
    "data_one_hot = input_data.read_data_sets(DATA_DIR, one_hot=True)\n",
    "\n",
    "data_classes = input_data.read_data_sets(DATA_DIR, one_hot=False)\n",
    "x_data, y_data = data_classes.train.images,data_classes.train.labels.astype(np.int32)\n",
    "x_test, y_test = data_classes.test.images,data_classes.test.labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels: one hot vs class number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('one-hot=False:\\n')\n",
    "print(data_classes.train.labels)\n",
    "print('\\n')\n",
    "print('one-hot=True:\\n')\n",
    "print(data_one_hot.train.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=10)]\n",
    "\n",
    "dnn = learn.DNNClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[200],\n",
    "    n_classes=10,\n",
    "    optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "      learning_rate=0.2,\n",
    "    ))\n",
    "\n",
    "fit = dnn.fit(x=x_data,y=y_data, steps=2000,batch_size=128)\n",
    "print('Done fitting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ev = dnn.evaluate(x=x_test,y=y_test, steps=1)[\"accuracy\"]\n",
    "print(ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " <tr>\n",
    "    <td> <img src=\"./img/mnist-digits-small.png\"  width=\"400\"/> </td>\n",
    "    <td> <img src=\"./img/acc_vs_n_units.png\"  width=\"600\"/> </td>\n",
    "    </tr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_pred = dnn.predict(x=x_test,as_iterable=False)\n",
    "class_names = ['0','1','2','3','4','5','6','7','8','9']    \n",
    "    \n",
    "    \n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=[8,6])\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Hands-on 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "x_data = preprocessing.StandardScaler().fit_transform(boston.data)\n",
    "y_data = boston.target\n",
    "y_data = y_data.reshape(y_data.shape + (1,))\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x_data, y_data, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Boston Housing dataset is a relatively small dataset (506 samples), containing information concerning housing in the area of Boston Massachusetts. There are 13 predictors and the target variable is the median value of owner-occupied homes in $1000's \n",
    "\n",
    "### Data Set Information:\n",
    "\n",
    "Concerns housing values in suburbs of Boston.\n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "1. CRIM: per capita crime rate by town \n",
    "2. ZN: proportion of residential land zoned for lots over 25,000 sq.ft. \n",
    "3. INDUS: proportion of non-retail business acres per town \n",
    "4. CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) \n",
    "5. NOX: nitric oxides concentration (parts per 10 million) \n",
    "6. RM: average number of rooms per dwelling \n",
    "7. AGE: proportion of owner-occupied units built prior to 1940 \n",
    "8. DIS: weighted distances to five Boston employment centres \n",
    "9. RAD: index of accessibility to radial highways \n",
    "10. TAX: full-value property-tax rate per \\$10,000 \n",
    "11. PTRATIO: pupil-teacher ratio by town \n",
    "12. B: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town \n",
    "13. LSTAT: % lower status of the population "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "feature_columns = learn.infer_real_valued_columns_from_input(x_data)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "\n",
    "regressor = learn.LinearRegressor(feature_columns=feature_columns,\n",
    "                                  optimizer=optimizer)\n",
    "\n",
    "##############################################\n",
    "# fit and evalute test data MSE for 1-20 steps\n",
    "##############################################\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(20),MSE,lw=3,alpha=0.5)\n",
    "plt.plot(np.arange(20),MSE,'ko',alpha=0.5)\n",
    "plt.title('Boston housing test data MSE',fontsize=20)\n",
    "plt.xlabel('# steps',fontsize=20)\n",
    "plt.ylabel('MSE',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/solution4.py\n",
    "\n",
    "feature_columns = learn.infer_real_valued_columns_from_input(x_data)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "\n",
    "regressor = learn.LinearRegressor(feature_columns=feature_columns,\n",
    "                                  optimizer=optimizer)\n",
    "\n",
    "MSE = []\n",
    "for i in range(20):\n",
    "    regressor.fit(x_train, y_train, steps=i, batch_size=506)\n",
    "    MSE.append(regressor.evaluate(x_test, y_test, steps=1)['loss'])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(20),MSE,lw=3,alpha=0.5)\n",
    "plt.plot(np.arange(20),MSE,'ko',alpha=0.5)\n",
    "plt.title('Boston housing test data MSE',fontsize=20)\n",
    "plt.xlabel('# steps',fontsize=20)\n",
    "plt.ylabel('MSE',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Keras\n",
    "Keras is one of the most popular and powerful TensorFlow extension libraries. In 2017 Keras gained official Google support, and as of version 1.1 is part of its contrib library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Installation\n",
    "\n",
    "~~~python \n",
    "pip install keras\n",
    "~~~\n",
    "\n",
    "Or download from:\n",
    "[Git page](https://github.com/fchollet/keras)\n",
    "\n",
    "And install using:\n",
    "\n",
    "~~~python \n",
    "python setup.py install\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Creating and running a model\n",
    "\n",
    "***1) We start by defining the shape of the input data***\n",
    "\n",
    "~~~python \n",
    "inputs = Input(shape=(784,))\n",
    "~~~\n",
    "\n",
    "***2) Then create layer, passing the input from one to the next***\n",
    "\n",
    "~~~python \n",
    "x = some layer(input)\n",
    "x = some layer(x)\n",
    "       ...\n",
    "       ...\n",
    "       ...\n",
    "outputs = last layer(x)\n",
    "~~~\n",
    "\n",
    "**3) And now instantiate the model, passing both inputs and outputs**\n",
    "\n",
    "~~~python \n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "~~~\n",
    "**4) Compile the* model, assigning it with an optimizer, a loss function and metrics***\n",
    "~~~python \n",
    "model.compile(optimizer='adadelta', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "~~~\n",
    "\n",
    "**5) fit by passing the data, and setting the number of epochs and batch size**\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=64)\n",
    "\n",
    "**6) Evaluate how it does**\n",
    "\n",
    "\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=64)\n",
    "\n",
    "**7) Predict new samples**\n",
    "\n",
    "classes = model.predict(x_test, batch_size=64)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Keras vs. Native Tensorflow\n",
    "\n",
    "### Native TensorFlow:\n",
    "\n",
    "~~~python \n",
    "initial = tf.truncated_normal([5, 5, 1, 32], stddev=0.1)\n",
    "W = tf.Variable(initial)\n",
    "initial = tf.constant(0, shape=32)\n",
    "b = tf.Variable(initial)\n",
    "img = nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "img = tf.nn.relu(img + b)\n",
    "~~~\n",
    "\n",
    "### Keras:\n",
    "\n",
    "~~~python \n",
    "init = keras.initializers.RandomNormal(mean=0.0, stddev=0.1)\n",
    "img = Conv2D(32, (5, 5),\n",
    "    activation='relu', \n",
    "    padding='same',\n",
    "    kernel_initializer=init,\n",
    "    bias_initializer='zeros'\n",
    "    )(inp_img)\n",
    "~~~\n",
    "\n",
    "### Native TensorFlow:\n",
    "\n",
    "~~~python \n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y_conv, labels = y_))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess =  tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(STEPS):\n",
    "    batch = mnist.train.next_batch(MINIBATCH_SIZE)\n",
    "\n",
    "    if i % 200 == 0:\n",
    "        valid_accuracy = sess.run(accuracy, \n",
    "                                  feed_dict={x: mnist.validation.images, \n",
    "                                             y_: mnist.validation.labels,\n",
    "                                             keep_prob: 1.0})        \n",
    "\n",
    "    sess.run(train_step, feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "    \n",
    "test_accuracy = np.mean([sess.run(accuracy, feed_dict={x:x_test, y_:y_test, \n",
    "~~~\n",
    "                                              keep_prob:1.0}) for i in range(10)])    \n",
    "### Keras:\n",
    "\n",
    "~~~python \n",
    "model.compile(optimizer='adadelta', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "                epochs=10,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, y_test)\n",
    "               )\n",
    "model.evaluate(x_test,y_test)\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# CNN for image classification (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/tmp/data' if not 'win32' in sys.platform else \"c:\\\\tmp\\\\data\"\n",
    "data = input_data.read_data_sets(DATA_DIR, one_hot=True)\n",
    "x_train, y_train = data.train.images,data.train.labels.astype(np.int32)\n",
    "x_test, y_test = data.test.images,data.test.labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, [-1, 28, 28, 1])\n",
    "x_test = np.reshape(x_test, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "inp_img = Input(shape=(28, 28, 1))  \n",
    "img = Conv2D(32, (5, 5), activation='relu', padding='same')(inp_img)\n",
    "img = MaxPooling2D((2, 2), padding='same')(img)\n",
    "img = Conv2D(64, (5, 5), activation='relu', padding='same')(img)             \n",
    "img = MaxPooling2D((2, 2), padding='same')(img)\n",
    "img = Flatten()(img)\n",
    "img = Dense(1024,activation=\"relu\")(img)\n",
    "img = Dropout(0.5)(img)\n",
    "decoded = Dense(10,activation=\"softmax\")(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnn = Model(inp_img, decoded)\n",
    "cnn.compile(optimizer='adadelta', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "cnn.fit(x_train, y_train,\n",
    "                epochs=5,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, y_test)\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_and_metrics = cnn.evaluate(x_test, y_test, batch_size=64)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# CNN for image classification (Cifar10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Autoencoders\n",
    "Output a reconstruction of the input after having its dimensionality reduced in the process\n",
    "\n",
    "Autoencoders create a bottleneck layer, called a hidden layer that has a smaller number of units than the input layer, forcing the data to be compressed before reconstructed. For the reconstruction (decoding) to be done efficiently, autoencoders extract representative features that capture some hidden abstraction.\n",
    "\n",
    "<img src=\"./img/autoencoders2.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Cifar10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take only images of class '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train[np.where(y_train==1)[0],:,:,:]\n",
    "x_test = x_test[np.where(y_test==1)[0],:,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converting our data to float32 and and normalize it to range between [0,1]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Then we add some Gaussian noise, and clip values that are either smaller than 0 or larger than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_train_n = x_train + 0.5 * np.random.normal(loc=0.0, scale=0.4, size=x_train.shape) \n",
    "x_test_n = x_test + 0.5 * np.random.normal(loc=0.0, scale=0.4, size=x_test.shape) \n",
    "\n",
    "x_train_n = np.clip(x_train_n, 0., 1.)\n",
    "x_test_n = np.clip(x_test_n, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(1,n):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(x_test_n[i])\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We declare the input layer (every image in CIFAR is 32x32 pixels with RGB channels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "inp_img = Input(shape=(32, 32, 3))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Our first layer is a 2D convolution layer, where the first argument is the number of filters (and thus the number of output images), and the second is the size of each filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "img= Conv2D(32, (3, 3), activation='relu', padding='same')(inp_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next, we add more \"legos\" layers: we add a 2x2 pooling layer , another convolution layer, an up-sampling (repeating the rows and columns of the data to get back the same number of pixels in each image), and finally a convolutional output layer where we go back to 3 channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "img = MaxPooling2D((2, 2), padding='same')(img)\n",
    "img = Conv2D(32, (3, 3), activation='relu', padding='same')(img)\n",
    "img = UpSampling2D((2, 2))(img)\n",
    "out_img = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We declare the functional model format, passing both inputs and ouputs. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "autoencoder = Model(inp_img, out_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We compile the model, declaring the loss function and the optimizer, in this case the Adagrad optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train_n, x_train,\n",
    "                epochs=10,\n",
    "                batch_size=64,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_n, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_imgs = 10\n",
    "f,axarr = plt.subplots(2,n_imgs,figsize=[20,10])\n",
    "decoded_imgs = autoencoder.predict(x_test_n)\n",
    "for i in range(n_imgs):\n",
    "    ax = axarr[0,i]\n",
    "    ax.imshow(x_test_n[i,:,:,:])\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax = axarr[1,i]\n",
    "    ax.imshow(decoded_imgs[i,:,:,:])\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "            \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising results for different epochs\n",
    "\n",
    "<img src=\"./img/denoising_cifar.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands on 2\n",
    "### Denoise MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise_factor = 0.5\n",
    "\n",
    "x_train_n = x_train + 0.5 * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_test_n = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "\n",
    "x_train_n = np.clip(x_train_n, 0., 1.)\n",
    "x_test_n = np.clip(x_test_n, 0., 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "input_img = Input(shape=(28, 28, 1))  \n",
    "\n",
    "\n",
    "- ***2D convolution with 32  3x3 filters + relu activation function***\n",
    "- *** max pooling with 2x2*** (compress)\n",
    "- ***2D convolution with 32  3x3 filters + relu activation function***\n",
    "- *** max pooling with 2x2*** (compress)\n",
    "\n",
    "\n",
    "- ***2D convolution with 32  3x3 filters + relu activation function***\n",
    "- *** max upsampling with 2x2*** (decompress)\n",
    "- ***2D convolution with 32  3x3 fil ters + relu activation function***\n",
    "- *** max upsampling with 2x2*** (decompress)\n",
    "- ***2D convolution with 1  3x3 filters + sigmoid activation function***\n",
    "\n",
    "\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_imgs = 10\n",
    "f,axarr = plt.subplots(2,n_imgs,figsize=[20,5])\n",
    "for i in range(n_imgs):\n",
    "    ax = axarr[0,i]\n",
    "    ax.imshow(x_test_n[i,:,:,0])\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax = axarr[1,i]\n",
    "    ax.imshow(decoded_imgs[i,:,:,0])\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "            \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/solution5.py\n",
    "\n",
    "\n",
    "\n",
    "input_img = Input(shape=(28, 28, 1))  \n",
    "im = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "im = MaxPooling2D((2, 2), padding='same')(im)\n",
    "im = Conv2D(32, (3, 3), activation='relu', padding='same')(im)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(im)\n",
    "\n",
    "\n",
    "im = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "im = UpSampling2D((2, 2))(im)\n",
    "im = Conv2D(32, (3, 3), activation='relu', padding='same')(im)\n",
    "im = UpSampling2D((2, 2))(im)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(im)\n",
    "\n",
    "model = Model(input_img, decoded)\n",
    "model.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "model.fit(x_train_n, x_train,\n",
    "                epochs=1,\n",
    "                batch_size=32,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_n, x_test))\n",
    "\n",
    "decoded_imgs = model.predict(x_test_n)\n",
    "\n",
    "n_imgs = 10\n",
    "f,axarr = plt.subplots(2,n_imgs,figsize=[20,5])\n",
    "for i in range(n_imgs):\n",
    "    ax = axarr[0,i]\n",
    "    ax.imshow(x_test_n[i,:,:,0])\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax = axarr[1,i]\n",
    "    ax.imshow(decoded_imgs[i,:,:,0])\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "            \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
