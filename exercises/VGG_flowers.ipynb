{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../notebooks/img/oscon.png\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this exercise we walk you through the task of classifying flowers in images. \n",
    "\n",
    "We will use a pre-trained VGG model for representing flower-images, and feed the output into a simple linear SVM (no image pre-processing other than chanel mean normalization).\n",
    "\n",
    "The <b>task</b> you will accomplish in this exercise was the content of a (very successful) PhD just under 10 years ago, demonstrating the huge leap in technical ability, as applied to the field of computer vision, brought about by CNNs. \n",
    "\n",
    "This exercise is highly demonstrative of the common practice of using deep learning for image classification problems with a pre-trained model and a much smaller specific labeled dataset. To get better results one might add some pre-processing, or a fancier classifier, but the power of CNNs is demonstrated by the out-of-the-box-ness of the solution, already acheiving over 80% accuracy.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### Materials: \n",
    "1. dataset: http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html\n",
    "(download 1 & 4; 336M)\n",
    "    Place the files under DATA_DIR\n",
    "2. VGG pretrained model for Keras (will be auto-downloaded upon first usage; ~60M)\n",
    "3. Ready-made represenation of the image dataset (this is just the representation of the images using the model from (2)): https://drive.google.com/drive/folders/0B3U30rvx_KQBSjVub3hreGt5blU\n",
    "\n",
    "---\n",
    "\n",
    "Place the dataset (1) and representation .csv (3) under IMAGE_DIR as defined below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from scipy.misc import imread, imresize\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/tmp/data' if not 'win' in sys.platform else \"c:\\\\tmp\\\\data\"\n",
    "IMAGE_DIR = os.path.join(DATA_DIR, \"flowers\")\n",
    "DEFAULT_VGG_IMAGE_SIZE = (224, 224)\n",
    "NUM_IMAGES = 8141\n",
    "NUM_CLASSES = 102"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a utility for reading a single image file, based on the file name. File names are such that:\n",
    "~~~python\n",
    "load_single_img(\"image_{:05}.jpg\".format(i+1))\n",
    "~~~\n",
    "will return the i-th image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_single_img(file_name, resize_to=DEFAULT_VGG_IMAGE_SIZE):\n",
    "    img = imread(os.path.join(IMAGE_DIR, \"jpg\", file_name))\n",
    "    img = imresize(img, resize_to)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a utility for generating a dataset with out of some or all of the 102 flower calsses. For instance:\n",
    "~~~python\n",
    "load_images_labels(use_classes=(21, 45, 68))\n",
    "~~~\n",
    "will generate a dataset with the classes 21, 45, and 68,\n",
    "~~~python\n",
    "load_images_labels(use_classes=None)\n",
    "~~~\n",
    "will generate a dataset with <b>all</b> the image classes in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_images_labels(use_classes=None, resize_to=DEFAULT_VGG_IMAGE_SIZE):\n",
    "\n",
    "    # Load the .mat label file\n",
    "    labels = loadmat(os.path.join(IMAGE_DIR, \"imagelabels.mat\"))[\"labels\"].ravel()\n",
    "\n",
    "    # If use_classes is None, it becomes all 102 available classes\n",
    "    use_classes = use_classes or list(range(NUM_CLASSES))\n",
    "\n",
    "    # Compile a list of flower-image files we are going to use, and the associated label in the format [(file, label),\n",
    "    file_name_label = [(\"image_{:05}.jpg\".format(i+1), labels[i])\n",
    "                       for i in range(NUM_IMAGES) if labels[i] in use_classes]\n",
    "\n",
    "    # Load images and labels\n",
    "    images = [load_single_img(file_name, resize_to=resize_to) for file_name, _ in file_name_label]\n",
    "    images = np.array(images)\n",
    "    labels = [l for _, l in file_name_label]\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Visualization \n",
    "Using the load_single_img method above, plot a 10X10 grid of random flower images from the dataset. Do you recongnize any of them? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. In this section we select a subset of the flower classes, and build a classifier for them using the pre-trained Keras VGG model and a linear SVM.\n",
    "\n",
    "### 2.1 Complete the VGGRep class defined below. \n",
    "When you are done, the .represent(images) method should return a numpy.Array with the VGG representation of `images`.\n",
    "\n",
    "### 2.2 Cross validated classifier results\n",
    "1. Select a small number (3-5 for instance) of classes out of the 102 flower types in the dataset. \n",
    "2. Run the VGG representation of the selected images. \n",
    "3. Using a crosss-validation procedure, determine the accuracy of a linear SVM applied to this representation.\n",
    "    \n",
    "    hint: use cross_val_score, and LinearSVC (imported above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class VGGRep(object):\n",
    "    def load(self):\n",
    "        m = VGG16(include_top=False, weights='imagenet', pooling='avg')\n",
    "        m.compile(SGD(), 'categorical_crossentropy')\n",
    "        m.summary()\n",
    "        self._m = m\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def pre_process(image):\n",
    "        # Subtract the TRAINING-DATA mean -- not completely necessary but helps. \n",
    "        image[:, :, 0] -= 103.939\n",
    "        image[:, :, 1] -= 116.779\n",
    "        image[:, :, 2] -= 123.680\n",
    "        return image\n",
    "\n",
    "    def represent_single_image(self, image):\n",
    "        \"\"\"\n",
    "        :param image: an image array of shape (224, 224, 3)\n",
    "        --\n",
    "        :return: The VGG representation of image\n",
    "        \"\"\"\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "        return vgg_representation\n",
    "\n",
    "    def represent(self, images):\n",
    "        \"\"\"\n",
    "        :param images: mlutple images; shape (None, 224, 224, 3)\n",
    "        --\n",
    "        :return: The VGG representation of images. Shape should be (None, 512)\n",
    "        \"\"\"\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "        return vgg_representation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we use VGGRep in order to represent a sub-set of the flower classes, and use a linear SVM to classify them. We evaluate this with a cross-validation procedure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The 4-class version\n",
    "CLASSES_TO_USE = (77, 78, 79, 80)\n",
    "images, labels = load_images_labels(use_classes=CLASSES_TO_USE, \n",
    "                                    resize_to=DEFAULT_VGG_IMAGE_SIZE)\n",
    "print(images.shape)\n",
    "\n",
    "# TODO: make VGG representation of images \n",
    "# TODO: cross validation with LinearSVM\n",
    "\n",
    "\n",
    "print(\"Overall percent correct: {:.4f}%\".format(pcorr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. In this section we classify all 102 flower calsses\n",
    "Since running the VGG network to represent all 8141 images in the dataset may take too long, we have prepared a .csv file (vgg_rep.csv) containing the representation of the entire dataset: \n",
    "- The index column is the label (class number)\n",
    "- The header contains the feature number (0-511 -- for the 512 features in the VGG representation we are using)\n",
    "\n",
    "### 3.1 Classify the entire dataset\n",
    "Repeat the procedure from section 2.2(3) and determine how well the linear SVM applied to the VGG representation is able to classify the entire 102 classes of flower images.\n",
    "\n",
    "### 3.2 Classift arbitrary flowers\n",
    "Now train a single LinearSVM model on all the data. Download a few images from the internet (belonging to classes in the dataset). After resizing them to the appropreate dimensions (DEFAULT_VGG_IMAGE_SIZE), does the model label them correctly?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The 102-class version \n",
    "vgg_rep_all = pd.read_csv(os.path.join(IMAGE_DIR, \"vgg_rep.csv\"), index_col=0, header=0)\n",
    "X = vgg_rep_all.values\n",
    "y = vgg_rep_all.index\n",
    "\n",
    "# TODO: cross validation procedure \n",
    "\n",
    "print(\"Overall percent correct: {:.4f}%\".format(pcorr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, train a single LinearSVM on all the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: train LinearSVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: check classifitaion on some flower images from the web"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
